{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech Enhancement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对比三个效果最明显的语音增强模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 记录推理时间\n",
    "import time\n",
    "time_start = time.perf_counter()  # 记录开始时间\n",
    "# function()   执行的程序\n",
    "time_end = time.perf_counter()  # 记录结束时间\n",
    "time_sum = time_end - time_start  # 计算的时间差为程序的执行时间，单位为秒/s\n",
    "print(\"cpu运行程序时间: \", time_sum * 1000, \" ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denoiser facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display as disp\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "from denoiser import pretrained\n",
    "from denoiser.dsp import convert_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pretrained.dns64()\n",
    "# wav, sr = torchaudio.load(\"/Users/yuexiajiao/Downloads/gtcrn-main/stream/test_wavs/mix.wav\")\n",
    "wav, sr = torchaudio.load(\"/Users/yuexiajiao/Downloads/noisy_trainset_28spk_wav/p226_007.wav\")\n",
    "\n",
    "wav = convert_audio(wav, sr, model.sample_rate, model.chin)\n",
    "print(sr)\n",
    "\n",
    "with torch.no_grad():\n",
    "    denoised = model(wav[None])[0]\n",
    "disp.display(disp.Audio(wav.data.cpu().numpy(), rate=model.sample_rate))\n",
    "disp.display(disp.Audio(denoised.data.cpu().numpy(), rate=model.sample_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SEGAN+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from pre_model.segan.models import *\n",
    "from pre_model.segan.datasets import *\n",
    "import soundfile as sf\n",
    "from scipy.io import wavfile\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import random\n",
    "import librosa\n",
    "import matplotlib\n",
    "import timeit\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgParser(object):\n",
    "\n",
    "    def __init__(self, args):\n",
    "        for k, v in args.items():\n",
    "            setattr(self, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(opts):\n",
    "    assert opts.cfg_file is not None\n",
    "    assert opts.test_files is not None\n",
    "    assert opts.g_pretrained_ckpt is not None\n",
    "\n",
    "    with open(opts.cfg_file, 'r') as cfg_f:\n",
    "        args = ArgParser(json.load(cfg_f))\n",
    "        print('Loaded train config: ')\n",
    "        # print(json.dumps(vars(args), indent=2))\n",
    "    args.cuda = opts.cuda\n",
    "    if hasattr(args, 'wsegan') and args.wsegan:\n",
    "        segan = WSEGAN(args)     \n",
    "    else:\n",
    "        segan = SEGAN(args)     \n",
    "    segan.G.load_pretrained(opts.g_pretrained_ckpt, True)\n",
    "    if opts.cuda:\n",
    "        segan.cuda()\n",
    "    segan.G.eval()\n",
    "    if opts.h5:\n",
    "        with h5py.File(opts.test_files[0], 'r') as f:\n",
    "            twavs = f['data'][:]\n",
    "    else:\n",
    "        # process every wav in the test_files\n",
    "        if len(opts.test_files) == 1:\n",
    "            # assume we read directory\n",
    "            twavs = glob.glob(os.path.join(opts.test_files[0], '*.wav'))\n",
    "        else:\n",
    "            # assume we have list of files in input\n",
    "            twavs = opts.test_files\n",
    "            print(len(twavs))\n",
    "    print('Cleaning {} wavs'.format(len(twavs)))\n",
    "    beg_t = timeit.default_timer()\n",
    "    for t_i, twav in enumerate(twavs, start=1):\n",
    "        if not opts.h5:\n",
    "            tbname = os.path.basename(twav)\n",
    "            rate, wav = wavfile.read(twav)\n",
    "            wav = normalize_wave_minmax(wav)\n",
    "        else:\n",
    "            tbname = 'tfile_{}.wav'.format(t_i)\n",
    "            wav = twav\n",
    "            twav = tbname\n",
    "        wav = pre_emphasize(wav, args.preemph)\n",
    "        pwav = torch.FloatTensor(wav).view(1,1,-1)\n",
    "        if opts.cuda:\n",
    "            pwav = pwav.cuda()\n",
    "        g_wav, g_c = segan.generate(pwav)\n",
    "        out_path = os.path.join(opts.synthesis_path,\n",
    "                                tbname) \n",
    "        if opts.soundfile:\n",
    "            sf.write(out_path, g_wav, 16000)\n",
    "        else:\n",
    "            wavfile.write(out_path, 16000, g_wav)\n",
    "        end_t = timeit.default_timer()\n",
    "        print('Cleaned {}/{}: {} in {} s'.format(t_i, len(twavs), twav,\n",
    "                                                 end_t-beg_t))\n",
    "        beg_t = timeit.default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--g_pretrained_ckpt', type=str, default=\"/Users/yuexiajiao/Desktop/DailyReport/pre_model/segan/ckpt_segan+/segan+_generator.ckpt\")\n",
    "    parser.add_argument('--test_files', type=str, nargs='+', default=\"/Users/yuexiajiao/Desktop/DailyReport/test_waves/dpcrn-compress\")\n",
    "    parser.add_argument('--h5', action='store_true', default=False)\n",
    "    parser.add_argument('--seed', type=int, default=111, \n",
    "                        help=\"Random seed (Def: 111).\")\n",
    "    parser.add_argument('--synthesis_path', type=str, default=\"/Users/yuexiajiao/Desktop/DailyReport/test_waves/segan+\",\n",
    "                        help='Path to save output samples (Def: ' \\\n",
    "                             'segan_samples).')\n",
    "    parser.add_argument('--cuda', action='store_true', default=False)\n",
    "    parser.add_argument('--soundfile', action='store_true', default=False)\n",
    "    parser.add_argument('--cfg_file', type=str, default=\"/Users/yuexiajiao/Desktop/DailyReport/pre_model/segan/ckpt_segan+/train.opts\")\n",
    "\n",
    "    opts = parser.parse_args([])\n",
    "\n",
    "    if not os.path.exists(opts.synthesis_path):\n",
    "        os.makedirs(opts.synthesis_path)\n",
    "    \n",
    "    # seed initialization\n",
    "    random.seed(opts.seed)\n",
    "    np.random.seed(opts.seed)\n",
    "    torch.manual_seed(opts.seed)\n",
    "    if opts.cuda:\n",
    "        torch.cuda.manual_seed_all(opts.seed)\n",
    "\n",
    "    main(opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH=\"synth_segan+\"\n",
    "\n",
    "python -u clean.py --g_pretrained_ckpt $CKPT_PATH/$G_PRETRAINED_CKPT \\\n",
    "\t--test_files $TEST_FILES_PATH --cfg_file $CKPT_PATH/train.opts \\\n",
    "\t--synthesis_path $SAVE_PATH --soundfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DRCRN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DPCRN Compressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import soundfile as sf\n",
    "from pre_model.gtcrn import GTCRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load model\n",
    "device = torch.device(\"cpu\")\n",
    "# model = GTCRN().eval()\n",
    "ckpt = torch.load(os.path.join('pre_model/gtcrn', 'model_trained_on_dns3.tar'), map_location=device)\n",
    "# model.load_state_dict(ckpt['model'])\n",
    "# print(model)\n",
    "model = GTCRN()\n",
    "# print(model)\n",
    "## load data\n",
    "mix, fs = sf.read('/Users/yuexiajiao/Desktop/DailyReport/test_waves/noisy_test/p226_002_16k.wav', dtype='float32')\n",
    "# 因为模型的默认输入是16000Hz，所以这里需要对48kHz重新适配采样率\n",
    "# assert fs == 16000\n",
    "print(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 降采样\n",
    "import librosa\n",
    "# to install librosa package\n",
    "# > conda install -c conda-forge librosa \n",
    "\n",
    "newFilename = '/Users/yuexiajiao/Desktop/DailyReport/test_waves/noisy_test/p226_002_16k.wav'\n",
    "\n",
    "y, sr = librosa.load('/Users/yuexiajiao/Desktop/DailyReport/test_waves/noisy_test/p226_002.wav', sr=48000)\n",
    "y_8k = librosa.resample(y, orig_sr=sr, target_sr=16000)\n",
    "\n",
    "import soundfile as sf\n",
    "sf.write(newFilename, y_8k, 16000)\n",
    "\n",
    "# librosa.output.write_wav(newFilename, y_8k, sr=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## inference\n",
    "input = torch.stft(torch.from_numpy(mix), 512, 256, 512, torch.hann_window(512).pow(0.5), return_complex=False)\n",
    "# print(input[None].shape)\n",
    "# print(input.shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input[None])[0]\n",
    "#     print(output.shape)\n",
    "# print(output.shape)\n",
    "# output = torch.view_as_complex(output)\n",
    "enh = torch.istft(output, 512, 256, 512, torch.hann_window(512).pow(0.5))\n",
    "\n",
    "## save enhanced wav\n",
    "sf.write(os.path.join('/Users/yuexiajiao/Desktop/DailyReport/test_waves/dpcrn-compress/enh.wav'), enh.detach().cpu().numpy(), fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display as disp\n",
    "disp.display(disp.Audio(mix, rate=16000))\n",
    "disp.display(disp.Audio(enh, rate=16000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
