# 6.28日报

## 完成工作

### speech-enhancement

1. 分析模型的数据结果，并统计其他论文中使用相同数据集的结果，结果统计在微盘介绍中
2. 分析模型的时频谱结果，如下图所示
3. 压缩模型，用onnxsim库继续压缩模型算子
4. 撰写该模型的分析报告，之后将具体从参数对比、wav时频谱图、以及听力直观感受方面汇总完整的汇报，已提交微盘共享链接。

### 下一步计划

1. 对于48kHz的数据集，需要修改模型的结构，比如channel与stft的窗宽与采样点数，换数据集继续跑，生成多组对照。
2. 下周需要继续完善情绪识别与情绪融合的模型，今天模型因为stft的实数虚数的冲突问题一直跑不起来，之后需要继续满足input_size的需求。
整理情绪识别的压缩模型的汇报。

### 模型泛化

1. 如果想要用48kHz的数据集进行训练，转换到48k是需要修改模型。
   1. 对于48k数据，如果STFT沿用32ms帧长的设置，频率维度将会是769个点而不是257个点。需要考虑参数的改动
   2. 在频谱压缩BM模块，对多少kHz以下的频带不进行压缩？
   3. 输入的频谱通过Encoder之后，频率维度是多少？要相应地调整Bottleneck的G-DPRNN的参数
   4. 可能还存在其它没考虑到的修改。待补充。。。

### onnx改进

1. SFE模块的unfold可以用如下模块代替，可以减少很多算子

    ```python
    import torch
    import torch.nn as nn
    class Unfold(nn.Module):
        def __init__(self):
            super().__init__()
            kernel = torch.eye(3)
            kernel = kernel.view(3, 1, 1, 3)
            kernel = nn.Parameter(kernel.repeat(8, 1, 1, 1))
            self.conv = nn.Conv2d(8, 24, (1, 3), padding=(0, 1), groups=8, bias=False)
            self.conv.weight = kernel
            
        def forward(self, x):
            out = self.conv(x)
            return out
    ```

2. onnxsim没办法把ConvTranspose和BN融合在一起，但是pnnx可以，可以节省算力，用如下方法导出若干文件

    ```python
    import pnnx
    mod = torch.jit.trace(model_stream, [一堆变量])
    mod.save("xxx.pt")
    opt_net = pnnx.convert("xxx.pt", [一堆变量])
    ```

3. 然后会在当前文件夹生成一个gtcrn_pnnx.py的文件，里面有一个export_onnx()的函数，可以按喜好修改输出形式，最后当然也可以用onnxsim再跑一次

    ```python
    export_onnx()
    import onnx
    from onnxsim import simplify
    onnx_model = onnx.load('xxx.onnx')
    onnx.checker.check_model(onnx_model)
    model_simp, check = simplify(onnx_model)
    onnx.save(model_simp, 'xxx_sim.onnx')
    ```
