# 7.4日报

## speech-enhancement

1. 音质增强：最终选定6个模型进行音质增强，大小涵盖多样，数据集都是20GB-45小时音频（含噪声线性叠加与纯净音频）。
2. 以onnx从大到小分别为：
   1. SEGAN+模型1.02GB，因为加入了transformer多层编码机制，效果最好；
   2. GAN+Dense Block模型512MB，有效防止了loss变为nan的情况；
   3. Denoiser模型373MB，训练较快，120epoch时即可收敛；
   4. DeepFilter模型分为三个版本，大小在134MB附近，音频起点处有噪声，后面正常；
   5. DRCRN模型7.37MB，因为针对的是16kHz输入，又重新训练了一下发现对48kHz效果不好
   6. 新模型后面加入了一些模块，比如多头注意力、乘性加权，会提升一点点效果。
3. 对DRCRN进行full band魔改，大小11.1MB，从音频的物理特性出发，基于声学perception感知设计滤波器组，mel scale、erb filter、bark等，对频谱进行压缩。缺点是在推理时会多一步stft与istft。最后的推理结果：10s音频不到1ms，时长超过4分钟爆显存，cpu推理超过1分钟。
4. 存在问题：在信噪比在-5dB至5dB范围内效果可以，但是高音与低音频繁消失。且后续要考虑移动端部署real to time的效果。

## 下一步计划

1. 尝试音频切片：第一种方法是定时切片，第二种是基于语音停顿切片
2. 检查模型鲁棒性，是不是对高音和低音都有过度消除的效果
3. 增加滤波器组，缓解模型对低频信号的集中学习
