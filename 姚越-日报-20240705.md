# 7.5日报

## speech-enhancement

1. 音频切片功能测试：
   1. 基于pydub库按照固定时长片段切片，按照语音停顿位置切片
   2. 如果按照停顿切片会有一些bug：具体是个人音频参数不好确定，比如：停顿时长阈值、语音响度阈值、补0时长等等。如果不同场景声音响度区别太大会导致无法切片
   3. 基于ffmpeg进行音频切片，
2. 完善模型通用代码模板，从dataset到trainer，从train到test，到inference，再到evaluation
3. 发现了一个新的bug：模型训练后的结果只对48kHz采样率的音频有效，如果要更换成44.1kHz音频，需要重新计算频谱映射参数。在测试的过程中，如果对44.1kHz音频进行推理，会出现时长被压缩的问题，肯定不同步。同时根据ffmpeg导出的音频info，发现采样率是48kHz，但实际采样点数是44.1kHz，所以推测是infer代码中采样率转换的问题，需要进一步测试。
4. 模型处理对象虽然针对48kHz，后面在write的过程中尝试以44.1kHz写入也是可以的。

## 了解Zero-Shot，Few-Shot，One-Shot

1. 基于机器学习对样本的需求分为：传统监督式学习、Zero-Shot、Few-Shot、One-Shot
2. 传统监督式学习：海量数据+反复训练
3. zeroshot：已经具备利用训练集数据训练模型，使得模型能够对测试集的对象进行分类，但是训练集类别和测试集类别之间没有交集；期间需要借助类别的描述，来建立训练集和测试集之间的联系，从而使得模型有效。ZSL就是希望我们的模型能够对其从没见过的类别进行分类，让机器具有推理能力，实现真正的智能。其中零次（Zero-shot）是指对于要分类的类别对象，一次也不学习。
4. Zero-shot：仅使用当前任务的自然语言描述，不进行任何梯度更新；
5. One-shot：当前任务的自然语言描述，加上一个简单的输入输出样例，不进行任何梯度更新；
6. Few-shot：当前任务的自然语言描述，加上几个简单的输入输出样例，不进行任何梯度更新；

## 下一步

1. 对于现在的数据集20G，10h，10000条数据，还需要进一步扩充数据。
2. 在低SNR场景中，模型的过滤效果太强了，导致人声和噪声一起滤掉，这也是SE模型的通病。
3. 汇总微盘内noisy case信号，整理出结果放到微盘中，包括48kHz、44.1kHz、单双声道。
