# 7.6日报

## speech-enhancement

1. 重新编写了一套通用型基于深度学习的语音增强代码，从dataloader，到trainer，到evaluate，最后inference。优点是拥有固定的模板，将noisy和clean数据用csv进行管理，保持语音长度固定在10s，所以后面实时推理过程中歌声数据最长也是10s。
2. 如果后期需要重新训练或者训练其他种类的模型，只需要修改model.py文件即可。
3. 扩充现阶段的性能评价指标，加入DNSMOS指标评价语音增强效果。
4. 音频切片功能测试：
   1. 基于pydub库按照固定时长片段切片，按照语音停顿位置切片。
   2. 基于ffmpeg进行音频切片，命令行处理速度更快。

## 下一步计划

1. 将RNN模型换成DPRNN与DPCRN重新训练，其中的channel与矩阵的维度需要重新计算。
2. 针对微盘中的低SNR歌声信号着重处理，因为之前的模型始终对低SNR信号有过度的抑制作用，导致人声也听不到。
3. 对于现在的数据集20G，10h，10000条数据，还需要进一步扩充数据。
4. 在低SNR场景中，模型的过滤效果太强了，导致人声和噪声一起滤掉，这也是SE模型的通病。
5. 汇总微盘内noisy case信号，整理出结果放到微盘中，包括48kHz、44.1kHz、单双声道。
