# # 7.11日报

## speech-enhancement

1. 针对上周出现的音质增强后的问题进行集中修改：
   1. 高音被压低、低音变无声：之前模型过度依赖dense block缓解梯度消失问题
   2. 推理长度与实际长度每秒有34帧数的差异：wav文件的头没有在推理代码中预处理
   3. 只能推理48kHz的音频，无法对44.1kHz进行处理：预设置的频谱矩阵
2. 整理了语音增强的所有效果，包括多种类型：
   1. 44.1kHz，5s，10s，30s，60s，整段长度
   2. 48kHz，5s，10s，30s，60s，整段长度
   3. 在小尺寸模型中做了对比，集中测试了pesq等参数，但是由于pesq只支持8/16kHz音频输入，所以将不同模型的48kHz输出转为16kHz进行计算，其余参数比如stoi、mel loss等都有略微的优势。
3. 模型最大的优势在于推理速度与实时因果性：
   1. 推理10s音频需要3s，RTF参数（处理一段长度为a的音频信号需要花费时间b）是0.3，满足实时性要求。如果对一段3min音频以10s定长切片，最后再进行合并，最后总时间是1min。
   2. 将BN层替换为LN层，不需要集中对输入进行计算，当前推理值只与之前或当前值有关
4. 模型的大小：
   1. pt：4.4MB，pth：10.5MB
   2. onnx：3.4MB， tensorRT：3.3MB
   3. coreml：mlmodel：3.7MB，mlpackage：2.1MB
5. 存在一些问题：1. 低信噪比情境下降噪效果不明显，或者是会把人声一起过滤掉；2. 如果周围有人讲话，且响度和干声差不多，也无法过滤干净。3. 瞬态、特别响的噪音（比如耳机手机话筒掉地上、工厂车间内）也无法明显消除。
6. 修改数据集重跑：之前的数据集是（纯净人声+干扰人声）（纯净人声人声+噪音）的随机叠加，修改为（纯净声音+噪音+旁人声音）随机混合，不确定能不能收敛。
